=  Kafka连接器
:keywords: apache kafka connector, user guide, apachekafka, apache kafka
：imagesdir：./_images

link:http://kafka.apache.org/090/documentation.html[阿帕奇卡夫卡]的Anypoint连接器允许您与Apache Kafka邮件系统进行交互，使用Mule运行时实现Mule应用程序和Apache Kafka集群之间的无缝集成。

http://mulesoft.github.io/mule-kafka-connector/[技术参考和演示App下载] +
link:/release-notes/kafka-connector-release-notes[Kafka连接器发行说明]

阅读本用户指南以了解如何使用Apache Kafka连接器设置和配置基本Mule流。

*Note:*
使用 link:/release-notes/kafka-connector-release-notes[连接器发行说明]跟踪每个版本的连接器的功能添加，兼容性，限制和API版本更新。使用 link:http://mulesoft.github.io/mule-kafka-connector/[技术参考]和https://www.anypoint.mulesoft.com/exchange/?search=kafka[Anypoint Exchange]查看连接器操作和功能。

MuleSoft在 link:/mule-user-guide/v/3.9/anypoint-connectors#connector-categories[_选择_]支持策略下维护此连接器。


== 先决条件

本文假设您熟悉Mule， link:/mule-user-guide/v/3.9/anypoint-connectors[Anypoint连接器]和 link:/anypoint-studio/v/6/[Anypoint Studio Essentials]为了提高您对Studio的熟悉度，请考虑完成一个或多个 link:/anypoint-studio/v/6/basic-studio-tutorial[Anypoint Studio教程]。此外，本页假定您对 link:/mule-user-guide/v/3.9/elements-in-a-mule-flow[骡流]和 link:/mule-user-guide/v/3.9/global-elements[全球元素]有基本的了解。


=== 硬件和软件要求

有关硬件和软件要求，请参阅 link:/mule-user-guide/v/3.9/hardware-and-software-requirements[Mule硬件和软件要求]页面。

=== 兼容性

[width="100%",cols=",",options="header"]
|===
|应用/服务 |版本
| Mule Runtime  |  3.7.0及更高版本
| Apache Kafka  |  0.10.2.0
|===


== 安装Kafka连接器

您可以使用 link:/anypoint-studio/v/6/import-asset-exchange-task[从Exchange导入资产]中的说明在Anypoint Studio中安装此连接器。

[[configure]]
== 配置Kafka连接器全局元素

要在Mule应用程序中使用Apache Kafka连接器，必须首先为Kafka连接器配置全局元素。我们将向您展示如何使用Anypoint Studio UI完成此操作。

*Notes:*

* 该全局元素可以被应用程序中的所有Kafka连接器使用（详细了解 link:/mule-user-guide/v/3.9/global-elements[全球元素]）。

* 并非所有连接器实例都必须使用相同的全局元素/配置。 *multiple connectors in a flow, using different global elements/configurations*连接到一个或不同的实例并不罕见。


您必须在*Global Element Properties*窗口中提供连接和其他详细信息 - 这些设置保存在全局元素中，并由适用的连接器实例引用：

。示例使用属性占位符 - 实际值存储在`.properties`文件中
image:user-manual-aa82e.png[组态]

在上面的图片中，占位符值是指保存在`.properties`文件中的值，默认情况下存在于项目的`src/main/resources`文件夹中（请参阅 link:/mule-user-guide/v/3.9/configuring-properties[配置属性]）。

为了便于维护和连接器属性的可重用性，我们建议您使用`.properties`文件。如果您需要将应用程序部署到不同的环境中，例如生产，开发和质量保证（您的访问凭据可能不同），请避免在全局元素中对其进行硬编码。有关更多信息，请参阅 link:/mule-user-guide/v/3.9/deploying-to-multiple-environments[部署到多个环境]。


Kafka Connector的=== 全局元素属性

[%header,cols="1,1a",frame=topbot]
|===
| {字段{1}}说明
| *Name*  | 为此连接器配置输入一个名称，以便以后可以引用它。
用于建立与Kafka群集的初始连接的逗号分隔主机 - 端口对 - 与您向Kafka客户端（生产者/消费者）提供的`bootstrap.servers`相同。| *Bootstrap Servers* {{4} 。如果提供了*Producer/Consumer Properties*个文件，则该值将被忽略，并使用来自属性文件的文件。
| *Consumer Properties File* | 您可以在其中设置用户的属性文件的路径 - 类似于您提供给Kafka命令行工具的内容。如果您未在属性文件中为`bootstrap.servers`指定值，则将使用*Bootstrap Servers*提供的值。另外，如果您未为`key.serializer`和`value.serializer`指定值，则它们将设置为`org.apache.kafka.common.serialization.StringDeserializer`。
| *Producer Properties File* | 您可以在其中设置生产者的属性文件的路径 - 类似于您提供给Kafka命令行工具的路径。如果您未在属性文件中为`bootstrap.servers`指定值，则将使用*Bootstrap Servers*提供的值。另外，如果您未为`key.serializer`和`value.serializer`指定值，则它们将设置为`org.apache.kafka.common.serialization.StringSerializer`。
|===


////
=== 升级到较新的连接器版本

如果您当前使用的是旧版本的连接器，Anypoint Studio的右下角将出现一个小弹出窗口，并带有"Updates Available"消息。

. 点击弹出框并查看可用更新。
. 点击连接器版本复选框，然后点击*Next*并按照用户界面提供的说明进行操作。
提示时，.  *Restart* Studio。
. 重新启动后，创建流程并使用Apache Kafka Connector时，如果您安装了多个版本的连接器，则可能会询问您要使用哪个版本。选择你想使用的版本。

另外，我们建议您使Studio保持最新版本。
////

== 使用Kafka连接器

Kafka连接器基于端点的概念。全局元素可以配置为：

*consuming messages from a topic*的入站端点，或* 
*pushing new key/message pairs to a topic*的{​​{0}}出站连接器。

=== 连接器命名空间和架构

在Studio中设计应用程序时，将连接器从调色板拖放到Anypoint Studio画布上的操作应自动使用连接器*namespace*和*schema location*填充Mule应用程序的XML代码。


*Namespace:*

[source, xml]
----
xmlns:apachekafka="http://www.mulesoft.org/schema/mule/apachekafka"
----

*Schema Location:*

[source, xml]
----
xsi:schemaLocation="http://www.mulesoft.org/schema/mule/apachekafka http://www.mulesoft.org/schema/mule/sfdc-composite/current/mule-apachekafka.xsd"
----

如果您是在Studio的XML编辑器或其他文本编辑器中手动编码Mule应用程序，请在`<mule>`标记内*Configuration XML*的标题中定义名称空间和模式位置。

[source, xml,linenums]
----
<mule xmlns="http://www.mulesoft.org/schema/mule/core"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xmlns:apachekafka="http://www.mulesoft.org/schema/mule/apachekafka"
      xsi:schemaLocation="
               http://www.mulesoft.org/schema/mule/core
               http://www.mulesoft.org/schema/mule/core/current/mule.xsd
               http://www.mulesoft.org/schema/mule/apachekafka http://www.mulesoft.org/schema/mule/apachekafka/current/mule-apachekafka.xsd">

      <!-- put your global configuration elements and flows here -->

</mule>
----


=== 在Mavenized Mule应用程序中使用连接器

如果您正在编写Mavenized Mule应用程序，则此XML片段必须包含在您的`pom.xml`文件中。

[source,xml,linenums]
----
<dependency>
  <groupId>org.mule.modules</groupId>
  <artifactId>mule-module-kafka</artifactId>
  <version>2.0.1</version>
</dependency>
----

在`<version>`标签内放置所需的版本号。迄今为止的可用版本是：

*  *2.0.1*
*  *2.0.0*
*  *1.0.2*
*  *1.0.1*
*  *1.0.0*

==  Kafka连接器示例用例

示例用例演练适用于Anypoint Studio用户。对于那些使用XML编写和配置应用程序的人来说，请直接跳转到示例Mule应用程序XML代码
link:#consume-xml[消费消息]或 link:#publish-xml[发布消息]来查看每个用例中如何在XML中配置Kafka全局元素和连接器。

== 消费来自卡夫卡主题的消息

了解如何使用连接器来使用主题中的消息，并按照以下格式将每条消费的消息记录到控制台："New message arrived: <message>"。

. 点击*File > New > Mule Project*创建一个新的Mule项目。
. 打开项目后，在Studio调色板中搜索您应该已经安装的Kafka连接器。将新的*Apache Kafka*连接器拖放到画布上。
[NOTE]
在这种情况下，Kafka连接器将被配置为使用来自主题的消息。
. 将*Apache Kafka*元素后面的*Logger*拖放到控制台中以记录传入的消息。
+
image:consumer_raw_flow.png[未配置的消费者流量]
+
. 双击流的标题并将其重命名为`consumer-flow`。
+
image:consumer_flow_config.png[消费者流程配置]
+
. 双击*Apache Kafka*连接器元素，并按如下所示配置其属性。
+
[%header%autowidth.spread]
|===
| {字段{1}}值
| *Display Name*  |卡夫卡消费者
| *Consumer Configuration*  | "Apache_Kafka__Configuration"（配置的默认名称，或您在 link:#configure[组态]部分中所述配置的任何其他配置
| *Operation*  |消费者
| *Topic*  | `${consumer.topic}`
| *Number of Partitions*  | `${consumer.topic.partitions}`
| *Partition Offsets MEL*  | `#[["0":"1","1":"2"]]`
|===
* 您可以使用MEL表达式将偏移量或偏移量传递给Kafka以从指定的偏移量或偏移量中重新检索消息。例如，＃[["0"："1"，"1"："2"]]表示将分区0的偏移量重置为1，将分区1的偏移量重置为2
+
image:consumer_config.png[卡夫卡消费者配置]
+
. 选择记录器并设置其字段，如下所示：
+
image:consumer_logger_config.png[消费者记录器配置]
+
. 在`/src/main/app/mule-app.properties`中输入有效的Apache Kafka属性，并使用属性占位符在那里标识它们：
.. 如果您按照 link:#configure[配置Kafka连接器全局元素]部分中的说明配置了Kafka全局元素，请为`config.bootstrapServers`，`config.consumerPropertiesFile`和`config.producerPropertiesFile`提供值。
.. 将`consumer.topic`设置为您要使用邮件的现有主题的名称。
.. 将`consumer.topic.partitions`设置为您在创建主题时为要使用邮件的主题设置的分区数。
. 现在您应该准备好在Studio的嵌入式Mule运行时（*Run As*> *Mule Application*）上部署应用程序。当一个新消息被推送到您设置`consumer.topic`的主题中时，您应该看到它在控制台中记录。

[[consume-xml]]
=== 消费来自卡夫卡主题的消息 -  XML

运行这个Mule应用程序，将连接器作为消费者，使用完成的XML代码，该代码将由您在上一节中完成的Studio工作生成：

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:apachekafka="http://www.mulesoft.org/schema/mule/apachekafka" 
xmlns="http://www.mulesoft.org/schema/mule/core" 
xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
xmlns:spring="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.springframework.org/schema/beans 
http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core 
http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/apachekafka 
http://www.mulesoft.org/schema/mule/apachekafka/current/mule-apachekafka.xsd">
    <apachekafka:config name="Apache_Kafka__Configuration" bootstrapServers="${config.bootstrapServers}" consumerPropertiesFile="${config.consumerPropertiesFile}" producerPropertiesFile="${config.producerPropertiesFile}" doc:name="Apache Kafka: Configuration"/>
    <flow name="new-projectFlow">
        <apachekafka:consumer config-ref="Apache_Kafka__Configuration" topic="${consumer.topic}" numberOfPartitions="${consumer.topic.partitions}" partitionOffsetsMEL="#[[&quot;0&quot;:&quot;1&quot;,&quot;1&quot;:&quot;2&quot;]]" doc:name="Kafka consumer"/>
        <logger message="New message arrived: #[payload]" level="INFO" doc:name="Consumed message logger"/>
    </flow>
</mule>
----

== 将消息发布到卡夫卡主题

使用连接器将消息发布到主题。

. 点击*File > New > Mule Project*创建一个新的Mule项目。
. 浏览项目结构并双击`src/main/app/project-name.xml`，然后执行以下步骤：
. 将新的*HTTP*元素拖放到画布上。这个元素将成为流的入口点，并将提供数据发送到主题。
. 在*HTTP listener*之后拖放一个新的*Apache Kafka*元素。
. 在*Apache Kafka*之后拖放一个新的*Set Payload*元素。此*Set Payload*元素将设置对HTTP请求的响应。
+
image:producer_raw_flow.png[未配置的生产者流程]
+
. 双击流标题（蓝线）并将流程的名称更改为"producer-flow"。
+
image:producer_flow_config.png[生产者流程配置]
+
. 选择*HTTP*元素。
. 点击"Connector Configuration"下拉菜单旁边的加号。
. 出现弹出窗口，接受默认配置并点击*OK*。
. 将*Path*设为`push`。
. 将*Display Name*设为`Push http endpoint`。
+
image:push_http_config.png[推送http配置]
+
. 选择*Apache Kafka*连接器并设置其属性，如下所示：
+
[%header%autowidth.spread]
|===
| *Display Name* |卡夫卡制片人
| *Consumer Configuration*  | "Apache_Kafka__Configuration"（配置的默认名称，或按照 link:#configuring[配置Kafka连接器全局元素]部分所述配置的任何其他配置）
| *Operation*  |生产者
| *Topic* | `#[payload.topic]`
| *Key* | `#[server.dateTime.getMilliSeconds()]`
| *Message* | `#[payload.message]`
|===
+
. 对于*Set Payload*元素：
.. 将*Display Name*设为`Set push response`
.. 将*Value*设为`Message successfully sent.`
+
image:producer_response_config.png[生产者响应配置]
+
. 现在我们必须为占位符提供值。
. 打开*`/src/main/app/mule-app.properties`*并为以下属性提供值：
.. 如果您按照 link:#configure[配置部分]中的说明配置了Kafka全局元素，然后为`config.bootstrapServers`，`config.consumerPropertiesFile`和`config.producerPropertiesFile`提供值
. 现在您可以部署应用程序。 （*Run As*> *Mule Application*）
. 要触发流并将消息推送到某个主题，请使用HTTP客户端应用程序，并将带有内容类型为"application/x-www-form-urlencoded"且正文为urlencoded格式的POST请求发送至`localhost:8081/push`。该请求应包含主题和消息的值。

您可以使用以下CURL命令：

`curl -X POST -d "topic=<topic-name-to-send-to>" -d "message=<message to push>" localhost:8081/push`

您可以使用在<<Consume Messages from Kafka Topic,Consume Messages from Kafka Topic>>示例中定义的其他示例应用来使用您正在生成的消息，并测试一切正常。


[[publish-xml]]
=== 将消息发布到Kafka主题 -  XML

运行此应用程序，以连接器作为消息发布者，使用完成的XML代码，该代码将由您在前一节中完成的Studio工作生成：

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>

<mule xmlns:http="http://www.mulesoft.org/schema/mule/http" xmlns:apachekafka="http://www.mulesoft.org/schema/mule/apachekafka" 
xmlns="http://www.mulesoft.org/schema/mule/core" 
xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
xmlns:spring="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.springframework.org/schema/beans 
http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core 
http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/apachekafka 
http://www.mulesoft.org/schema/mule/apachekafka/current/mule-apachekafka.xsd
http://www.mulesoft.org/schema/mule/http 
http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd">
    <apachekafka:config name="Apache_Kafka__Configuration" bootstrapServers="${config.bootstrapServers}" consumerPropertiesFile="${config.consumerPropertiesFile}" producerPropertiesFile="${config.producerPropertiesFile}" doc:name="Apache Kafka: Configuration"/>
    <http:listener-config name="HTTP_Listener_Configuration" host="0.0.0.0" port="8081" doc:name="HTTP Listener Configuration"/>
    <flow name="producer-flow">
        <http:listener config-ref="HTTP_Listener_Configuration" path="/push" doc:name="Push http endpoint"/>
        <apachekafka:producer config-ref="Apache_Kafka__Configuration" topic="#[payload.topic]" key="#[server.dateTime.getMilliSeconds()]" message="#[payload.message]" doc:name="Apache Kafka"/>
        <set-payload value="Message successfully sent." doc:name="Set push response"/>
    </flow>
</mule>
----

== 配置Kafka以使用Kerberos

. 下载并安装Kerberos KDC和Zookeeper。
+
安装后，确保您拥有以下主体`zookeeper/localhost@LOCALHOST`和`kafka/localhost@LOCALHOST`。这是localhost和realm LOCALHOST的示例，具体取决于您的KDC，它可能在`localhost@LOCALHOST`的最后部分中有所不同。您需要保存关联的密钥表文件，以便您可以通过为Zookeeper和Kafka启动的进程访问它们。
+
. 启动Kafka服务器。这假设你已经下载了Kafka服务器，KAFKA_HOME代表该服务器的主目录。
. 使用以下内容在KAFKA_HOME / config下创建zookeeper_server_jaas.conf文件：
+
[source,code,linenums]
----
Server {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  useTicketCache=true
  storeKey=true
  debug=true
  keyTab=PATH_TO_ZOOKEEPER_KEYTAB/zookeeper.keytab"
  principal="zookeeper/localhost@LOCALHOST";
};
----
+
将PATH_TO_ZOOKEEPER_KEYTAB替换为上述正确的文件夹路径以及后面的代码块。
+
在默认配置中，使用`Server`作为配置的标识符非常重要。
+
. 使用以下内容在KAFKA_HOME / config下创建kafka_server_jaas.conf文件：
+
[source,code,linenums]
----
KafkaServer {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  storeKey=true
  debug=true
  keyTab="PATH_TO_ZOOKEEPER_KEYTAB/kafka.keytab"
  principal="kafka/localhost@LOCALHOST";
};

// Zookeeper client authentication
Client {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    storeKey=true
    debug=true
    keyTab=”PATH_TO_ZOOKEEPER_KEYTAB/kafka.keytab"
    principal="kafka/localhost@LOCALHOST";
};
----
+
在默认配置中，使用`KafkaServer`和`Client`作为配置的标识符非常重要。 `KafkaServer`用于认证Kafka客户端，`Client`用于对Zookeeper进行自我认证。
+
. 将这两个属性添加到`KAFKA_HOME/config`下的`zookeeper.properties`：
+
[source,code,linenums]
----
authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
requireClientAuthScheme=sasl
----
+
这些在针对Zookeeper服务器的Kafka代理的Kerberos认证中启用。
+
.  将以下属性添加到`KAFKA_HOME/config`下的`server.properties`：
+
[source,code,linenums]
----
listeners=PLAINTEXT://:9092,SASL_PLAINTEXT://localhost:9093
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka
----
+
这些告诉kafka代理在端口9093上创建一个需要Kerberos认证的通道。
+
.  打开一个新终端并将目录更改为`KAFKA_HOME/bin`。
.  要启动Zookeeper，您必须使用以下值设置环境变量KAFKA_OPTS：
+
[source,code]
----
-Djava.security.krb5.conf=<path_to_krb_config>/krb5.conf -Djava.security.auth.login.config=../config/kafka_server_jaas.conf
----
+
例如：
+
[source,code]
----
export KAFKA_OPTS="-Djava.security.krb5.conf=../config/krb5.conf -Djava.security.auth.login.config=../config/kafka_server_jaas.conf”
----
+
krb5.conf文件包含Kerberos配置信息，包括感兴趣的Kerberos领域的KDC和管理服务器的位置。在Linux下，您通常可以在/etc/krb5.conf下找到它。
+
. 运行`./zookeeper-server-start(.sh/bat) ../config/zookeeper.properties`来启动zookeeper。
. 打开一个新终端并将目录更改为KAFKA_HOME / bin。
. 启动Kafka经纪人：运行：
+
[source,code]
----
./kafka-server-start(.sh/bat) ../config/server.properties
----
+
您应该在控制台中看到没有错误。
+
. 配置连接器。要从连接器内连接到Kafka，请将引导程序服务器设置为指向localhost：9093，并将以下属性与通常放置在这些文件中的其他属性一起放入consumer.properties和producer.properties中。
+
[source,code,linenums]
----
security.protocol=SASL_PLAINTEXT
sasl.mechanism=GSSAPI
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
      useKeyTab=true \
      storeKey=true  \
      debug=true \
      keyTab="PATH_TO_ZOOKEEPER_KEYTAB/kafka.keytab" \
      principal="kafka/localhost@LOCALHOST";
sasl.kerberos.service.name=kafka
----

== 另请参阅

*  https://help.ubuntu.com/lts/serverguide/kerberos.html [如何在Ubuntu上安装Kerberos]。
*  https://web.mit.edu/kerberos/krb5-1.12/doc/admin/conf_files/krb5_conf.html [MIT Kerberos Documentation  -  krb5.conf]。
*  https://kafka.apache.org/documentation/#security_sasl [了解Kafka SASL / Kerberos配置]。
* 访问 link:/release-notes/kafka-connector-release-notes[Apache Kafka连接器发行说明]。
* 详细了解 link:/mule-user-guide/v/3.8/anypoint-connectors[Anypoint连接器]。
* 请参阅 http://kafka.apache.org/documentation.html[Apache Kafka文档]
