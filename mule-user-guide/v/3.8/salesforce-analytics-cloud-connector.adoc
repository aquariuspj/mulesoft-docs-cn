=  Salesforce Analytics云连接器
:keywords: salesforce analytics cloud connector, user guide, sfdc

：imagesdir：。\ _图像
：图标：字体


用于Salesforce Analytics Cloud的Anypoint连接器允许您使用 link:https://developer.salesforce.com/docs/atlas.en-us.bi_dev_guide_ext_data.meta/bi_dev_guide_ext_data/[外部数据API]连接到Salesforce Analytics Cloud应用程序。该连接器提供了创建数据集并将其填充到Salesforce Analytics Cloud系统的便捷方法。将数据从许多不同的数据源加载到Analytics Cloud，无论它们是内部部署还是云端。使用此连接器超越.csv文件。

阅读本用户指南以了解如何使用连接器设置和配置基本集成流程。仔细阅读 http://mulesoft.github.io/mule-salesforce-analytics-connector/[技术参考]，了解连接器操作如何与外部数据API调用配合使用。

*Release Notes*： link:/release-notes/salesforce-analytics-cloud-connector-release-notes[Salesforce Analytics云连接器发行说明]。

== 先决条件

本文档假定您熟悉Mule，Anypoint连接器和Anypoint Studio。

== 要求

要使用Salesforce Analytics云连接器，您需要使用Salesforce Analytics云连接器，您必须拥有Salesforce帐户和必要的权限才能将数据上传到分析云中。有关更多信息，请参阅https://developer.salesforce.com/docs/atlas.en-us.bi_dev_guide_ext_data.meta/bi_dev_guide_ext_data/ [Analytics Cloud外部数据API开发人员指南]。


== 兼容性

[%header%autowidth.spread]
|===
|应用/服务 |版本
| Mule运行时 |  3.5.0及更高版本
|外部数据API  |  36.0
|===

== 安装和配置

=== 安装

. 在Anypoint Studio中，点击Studio任务栏中的Exchange图标。
. 点击Anypoint Exchange中的登录。
. 搜索连接器，然后单击安装。
. 按照提示安装连接器。

=== 在新项目中使用连接器

要在Mule应用程序项目中使用Salesforce Analytics Cloud连接器，请执行以下操作：

. 在Studio中，选择文件>新建> Mule项目。
. 为您的新项目输入一个名称，并将其余选项保留为默认值。
. 如果您打算使用Git，请为Studio项目选择*Create a .gitignore file*，然后单击*Next*以使用默认的.gitignore设置。
. 点击*Finish*创建项目。

=== 配置Salesforce Analytics云全局元素

要在您的Mule应用程序中使用Salesforce Analytics云连接器，您必须配置一个全局Salesforce Analytics云元素，供应用程序中的所有Salesforce Analytics云连接器使用（请阅读有关 link:/mule-user-guide/v/3.8/global-elements[全球元素]的更多信息）。

===  Salesforce Analytics云连接器身份验证

要访问Salesforce Analytics Cloud实例中的数据，您在身份验证方面有以下几种可能性：

* 基本认证
*  OAuth 2.0 Web Flow
*  OAuth 2.0 JWT承载者
*  OAuth 2.0 SAML承载

基本认证是最容易实现的。您只需在全局配置中提供凭据，然后在应用程序中的任何Salesforce Analytics Cloud连接器中引用全局配置。基本认证通常建议用于内部应用程序。另一方面，实现与OAuth 2.0相关的认证机制涉及一些额外的步骤，但如果您的服务暴露给外部用户，则可能会首选它，因为它可确保更好的安全性。有关这些认证机制的更多技术信息，请访问以下链接： link:https://developer.salesforce.com/docs/atlas.en-us.api.meta/api/sforce_api_calls_login.htm[基本身份验证]， link:https://help.salesforce.com/apex/HTViewHelpDoc?id=remoteaccess_oauth_web_server_flow.htm&language=en_US[OAuth 2.0 Web Flow]， link:https://help.salesforce.com/apex/HTViewHelpDoc?id=remoteaccess_oauth_SAML_bearer_flow.htm&language=en_US[OAuth 2.0 SAML承载]和 link:https://help.salesforce.com/HTViewHelpDoc?id=remoteaccess_oauth_jwt_flow.htm[OAuth 2.0 JWT持票人]。

. 点击画布底部的*Global Elements*标签。
. 在Global Mule配置元素屏幕上，点击*Create*。
. 在选择全局类型向导中，按"salesforce analytics"进行过滤，展开*Connector Configuration*，然后根据您的需要选择四种可用配置之一。
image:create_global_element.png[创建全局元素]

. 点击*Ok*
. 输入全局元素属性：
+
[NOTE]
======================
对于所有配置，代理支持如下：

[%header%autowidth.spread]
|===
| {字段{1}}说明
|主机 | 代理服务器的主机名。如果没有设置，则不使用代理。
|端口| 代理服务器运行的端口号。
|用户名| 登录服务器的用户名。如果没有设置，则不使用认证。
|密码| 登录服务器的用户名。
|===

======================

+

.. 对于*Salesforce Analytics Cloud: Basic Authentication*：
image:basic_authentication_config.png[基本认证配置]
+
注意：在上图中，占位符值是指放置在项目的*src*文件夹中的配置文件（了解如何 link:/mule-user-guide/v/3.8/configuring-properties[配置属性]）。您可以将您的凭证硬编码到全局配置属性中，也可以引用包含这些值的配置文件。为了更简单的维护和更好的项目重用性，Mule建议您使用配置文件。如果需要将这些值保存在单独的文件中，则需要将其部署到不同的环境，例如生产，开发和质量保证（访问凭证不同）。有关如何管理此操作的说明，请参阅 link:/mule-user-guide/v/3.8/deploying-to-multiple-environments[部署到多个环境]。
+
[%header%autowidth.spread]
|===
| {字段{1}}说明
|名称 | 为此连接器输入一个名称，以便稍后参考。
|用户名| 输入Salesforce Analytics Cloud用户名。
|密码| 输入相应的密码。
|安全令牌| 输入用户名的安全令牌。

注意：不要将基本身份验证中所需的安全令牌与OAuth身份验证中所需的安全令牌混淆。在这里，令牌是指您的用户，而不是您的应用程序，就像在OAuth中一样。
|读取超时 | 指定消费者在超时之前等待响应的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|连接超时 | 指定用户在超时前尝试建立连接的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|启用数据感知| 启用后， link:/anypoint-studio/v/6/datasense[DataSense]为Salesforce Analytics Cloud对象提取元数据，以自动确定应用程序必须提供或可从Salesforce Analytics Cloud获得的数据类型和格式系统。通过启用此功能，Mule可以发现您必须发送至或从Salesforce Analytics接收的数据类型。
|元数据文件名| 输入文件的路径，其中包含上载到Salesforce Analytics Cloud系统的行的对象结构描述。该路径必须与src / main / resources目录相关。它也可以是通配符，例如metadata / *。json，它将以".json"结尾的所有文件。
|===

.. 对于*Salesforce Analytics Cloud: Salesforce Analytics Cloud (OAuth)*：
... 在常规选项卡上，配置以下字段：
image:oauth_authentication_config.png[OAuth Web Flow]
+
[%header%autowidth.spread]
|===
| {字段{1}}说明
|名称 | 为此连接器输入一个名称，以便稍后参考。
|使用者密钥| 从Salesforce输入连接应用程序的使用者密钥。
|消费者秘密| 从Salesforce为您连接的应用输入消费者秘密。
|在无令牌| 选择连接器在找不到访问令牌时必须采取的操作。
|读取超时 | 指定消费者在超时之前等待响应的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|连接超时 | 指定用户在超时前尝试建立连接的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|启用数据感知| 启用后， link:/anypoint-studio/v/6/datasense[DataSense]为Salesforce Analytics Cloud对象提取元数据，以自动确定应用程序必须提供或可从Salesforce Analytics Cloud获得的数据类型和格式系统。通过启用此功能，Mule可以发现您必须发送至或从Salesforce Analytics接收的数据类型。
|元数据文件名| 输入文件的路径，其中包含上载到Salesforce Analytics Cloud系统的行的对象结构描述。该路径必须与src / main / resources目录相关。
|===
+
注意：有关如何创建连接的应用程序的更多信息，请参阅： link:https://help.salesforce.com/apex/HTViewHelpDoc?id=connected_app_create.htm[创建连接的应用程序]
+
... 在OAuth选项卡上，配置以下字段：
image:oauth_authentication_oauthtab.png[OAuth Web Flow OAuth选项卡]
+
[%header%autowidth.spread]
|===
| {字段{1}}说明
|域 | 输入用作回叫端点的域名。域名不是完整的URL，而是域名，IP地址或主机名。
|本地端口| 输入用于回叫端点的本地端口。
|远程端口| 输入用于构建回叫URL的远程端口。
|路径| 输入用于回叫端点的路径。
| Http连接器参考 | 输入用于回调端点的HTTP连接器参考。
|默认访问令牌ID  | 输入Mule Expression作为访问令牌。
|对象存储参考 | 输入对象存储参考的名称。
|===
+
.. 对于*Salesforce Analytics Cloud: OAuth 2.0 JWT Bearer*：
image:oauth_jwt_bearer_config.png[OAuth JWT持票人]
+
[%header%autowidth.spread]
|===
| {字段{1}}说明
|使用者密钥 | 从Salesforce输入连接应用程序的使用者密钥。
|密钥库 | 输入将用于签署JWT的java密钥库文件的路径。路径应该相对于src / main / resources文件夹。
|存储密码 | 输入上面提供的密钥存储的密码。
|主体 | 输入您将要代表的用户的用户名。
|令牌端点 | 输入提供令牌的服务器的URL。有关详情，请参阅： link:https://developer.salesforce.com/docs/atlas.en-us.api_rest.meta/api_rest/intro_understanding_oauth_endpoints.htm[了解OAuth端点]。
|读取超时 | 指定消费者在超时之前等待响应的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|连接超时 | 指定用户在超时前尝试建立连接的时间量（以毫秒为单位）。默认值是0，这意味着无限。
|启用数据感知| 启用后， link:/anypoint-studio/v/6/datasense[DataSense]为Salesforce Analytics Cloud对象提取元数据，以自动确定应用程序必须提供或可从Salesforce Analytics Cloud获得的数据类型和格式系统。通过启用此功能，Mule可以发现您必须发送至或从Salesforce Analytics接收的数据类型。
|元数据文件名| 输入文件的路径，其中包含上载到Salesforce Analytics Cloud系统的行的对象结构描述。该路径必须与src / main / resources目录相关。
|===

+

*How to generate a Keystore file*

+

[NOTE]
===============================
. 转到您的Mule工作区，并打开命令提示符（对于Windows）或终端（对于Mac）。
. 输入`keytool -genkeypair -alias salesforce-cert -keyalg RSA -keystore salesforce-cert.jks`，然后按Enter键。
. 输入以下详细信息：
.. 密钥存储的密码。
.. 您的名字和姓氏。
您的组织单位.. 。
.. 您所在城市的名称，州和您所在县的两个字母代码。
. 系统会在工作区中生成一个包含私钥/公钥对的java密钥库文件。您需要在连接器配置中为Keystore提供一个文件路径。
. 输入`keytool -exportcert -alias salesforce-cert -file salesforce-cert.crt -keystore salesforce-cert.jks`，然后按Enter键。
. 系统现在将公钥从密钥库导出到工作区中。这是您需要在Salesforce实例中输入的公钥。
. 确保您的工作区中有密钥库（salesforce-cert.jks）和公钥（salesforce-cert.crt）文件。
===============================
.. 对于*Salesforce Analytics Cloud: OAuth 2.0 SAML Bearer*：
image:oauth_saml_bearer_config.png[OAuth SAML承载者]
+
[%header%autowidth.spread]
|===
| {字段{1}}说明
|使用者密钥 | 从Salesforce输入连接应用程序的使用者密钥。
|密钥库 | 输入将用于签署JWT的java密钥库文件的路径。路径应该相对于src / main / resources文件夹。
|存储密码 | 输入上面提供的密钥存储的密码。
|主体 | 输入您将要代表的用户的用户名。
|令牌端点 | 输入提供令牌的服务器的URL。有关详情，请参阅： link:https://developer.salesforce.com/docs/atlas.en-us.api_rest.meta/api_rest/intro_understanding_oauth_endpoints.htm[了解OAuth端点]。
|读取超时 | 指定消费者在超时之前等待响应的时间量（以毫秒为单位）。默认值是0，这意味着无限期地等待。
|连接超时 | 指定用户在超时前尝试建立连接的时间量（以毫秒为单位）。默认值是0，这意味着无限期地等待。
|启用数据感知| 启用后， link:/anypoint-studio/v/6/datasense[DataSense]为Salesforce Analytics Cloud对象提取元数据，以自动确定应用程序必须提供或可从Salesforce Analytics Cloud获得的数据类型和格式系统。通过启用此功能，Mule可以发现您必须发送至或从Salesforce Analytics接收的数据类型。
|元数据文件名| 输入文件的路径，其中包含上载到Salesforce Analytics Cloud系统的行的对象结构描述。该路径必须与src / main / resources目录相关。
|===

+

*How to generate a Keystore file*

+

[NOTE]
===============================
. 转到您的Mule工作区，并打开命令提示符（对于Windows）或终端（对于Mac）。
. 输入`keytool -genkeypair -alias salesforce-cert -keyalg RSA -keystore salesforce-cert.jks`，然后按Enter键。
. 输入以下详细信息：
.. 密钥存储的密码。
.. 您的名字和姓氏。
您的组织单位.. 。
.. 您所在城市的名称，州和您所在县的两个字母代码。
. 系统会在工作区中生成一个包含私钥/公钥对的java密钥库文件。您需要在连接器配置中为Keystore提供文件路径。
. 输入`keytool -exportcert -alias salesforce-cert -file salesforce-cert.crt -keystore salesforce-cert.jks`，然后按Enter键。
. 系统现在将公钥从密钥库导出到工作区中。这是您需要在Salesforce实例中输入的公钥。
. 确保您的工作区中有密钥库（salesforce-cert.jks）和公钥（salesforce-cert.crt）文件。
===============================

=== 使用连接器

您可以将Salesforce Analytics Cloud连接器用作流中的出站连接器，以将数据推送到Salesforce Analytics Cloud系统。要将其用作出站连接器，只需将该连接器放置在入站端点之后的任意位置。请注意，您也可以在批处理中使用Salesforce Analytics Cloud连接器批量推送数据到Salesforce Analytics Cloud系统。

=== 用例

以下是Salesforce Analytics云连接器的常见用例：

. 在Salesforce Analytics Cloud系统中创建数据集，从输入文件中将数据上载到数据集中，然后触发系统开始处理数据。处理较小的文件时使用此项，最好小于10 MB。
. 在Salesforce Analytics Cloud系统中创建数据集，从输入文件中读取数据并将其拆分成批，将批量数据上载到数据集中，然后触发系统开始处理数据。我们推荐使用这种方法摄取大量的数据。确保批量提交大小小于或等于10 MB以获得最佳性能。如果批量提交大小大于10 MB，连接器将引发警告。

将====  Salesforce Analytics云连接器添加到流程中

. 在Anypoint Studio中创建一个新的Mule项目。
. 将Salesforce Analytics云连接器拖到画布上，然后选择它打开属性编辑器。
. 配置连接器的参数：

+

image:opeartion_config.png[分析操作配置]

+

[%header%autowidth.spread]
|===
| {字段{1}}说明
|显示名称 | 在应用程序中输入连接器的唯一标签。
|连接器配置 | 从下拉式选择中选择全局Salesforce Analytics连接器元素。
|操作 | 选择连接器执行的操作。
|===
+
. 保存您的配置。

== 示例用例

[tabs]
------
[tab,title="Studio Visual Editor"]
....

=== Example Use Case 1

Create a dataset and upload data into it by processing all the data in one big chunk.

Create a new Mule Project by clicking on *File > New > Mule Project*. In the new project dialog box, the only thing you are required to enter is the name of the project. Click on *Finish*.

image:new_project_dialog.png[New project dialog]

Now let's create the flow. Navigate through the project's structure and double-click on *src/main/app/project-name.xml* and follow the steps below:

. On the right side of studio search for *File*.
+
image:search_for_file.png[Search for File]
. Drag the *File* element onto the canvas.
. Search for *DataMapper* and drag it after *File*.
. Search for *Salesforce Analytics Cloud* and drag it after *DataMapper*.
. After completing the previous steps you should see:
+
image:all_flow_unconfigured.png[Unconfigured All In One flow]
. Let's start configuring each element. Double-click on the *File* element.
+
image:file_component.jpg[File component]
. Click on `...` next to the *Path* field.
. Choose a folder with only the csv file that you want to upload. You can download our example file and save it into chosen folder.
+
link:_attachments/CsvDemoTestData.csv[CsvDemoTestData.csv]
. Double-click on *Salesforce Analytics Cloud* connector.
. Click on the plus sign next to the *Connector configuration* dropdown.
+
image:create_data_set_config.jpg[Create data set config]
. A pop-up appears asking for type of configuration. Choose *Salesforce Analytics Cloud: Basic Authentication* option and click *OK*.
. A new pop-up appears asking for information required for basic authentication. For more info see the <<Installing and Configuring, Installing and Configuring>> section
+
image:basic_authentication_config.png[Basic Auth config]
. In the *Connection* section enter the credentials used to access the Salesforce instance.
. In the *DataSense metadata* section for the *Metadata file name* field enter the filename that describes the data structure you are going to upload. The filename has to be relative to the *src/main/resources* directory of your Studio project. For the file provided a few steps earlier (CsvDemoTestData.csv) you can use the metadata file provided below but do not forget to copy it into the *src/main/resources* directory.
+
link:_attachments/metadata.json[metadata.json]
. Click *OK* to return to the Salesforce Analytics Cloud tab.
. From the *Operation* dropdown in the *Basic Settings* section choose *Upload external data into new data set and start processing*.
. From the *Operation* dropdown in the *DataSet info* section choose *OVERWRITE*.
. In the *Description* enter *Test data set*.
. In the *Label* field under *DataSet info* enter *Test data set*.
. In the *Name* field under *DataSet info* enter *test_data_set*.
. Double-click on the *DataMapper* element.
. Click on the *Type* dropdown in the Input section and choose *CSV*
. Click on `...` next to the *CSV* field of the Input section and browse to the csv file in the same folder you selected for the *File* connector.
. Click the *Create mapping* button and you should see something similar to the picture below.
+
image:DM_mappings.png[Data mapper mappings]
. Now everything is set up and the application can be deployed.

It's time to test the app. Run the app in Anypoint Studio (Right-click on project name > *Run as > Mule Application*). Monitor the studio console and check Salesforce Wave Analytics UI to see if the data was uploaded.

==== Example Use Case 2

Create a dataset and upload data into it by processing the data in several chunks.

[NOTE]
When using the batch component tune it based on the amount of memory that you provide to the Mule ESB server.
If you use DataMapper, be sure that streaming is enabled, in order to avoid load the entire input in memory.
Bear in mind that default threading profile uses 16 threads and each thread is loading data in chunks of 100 records until it reaches the "Commit size" set on "Batch Commit" component.
You can minimize the memory used by decreasing the number of threads.
Finally you have to be aware of the fact that "Salesforce Analytics Cloud Connector" is also using some memory internally and you should tune "Commit Size" in order to find a good balance but do not set it too low because this will make it inefficient.

Create a new Mule Project by clicking on *File > New > Mule Project*. In the new project dialog box, the only thing you are required to enter is the name of the project. Click *Finish*.

image:new_project_dialog.png[New project dialog]

Now let's create the flow. Navigate through the project's structure and double click on *src/main/app/project-name.xml* and follow the steps below:

. On the right side of Studio search for *Batch*.
+
image:search_for_batch.jpg[Search for batch]
. Select *Batch* and drag it onto the canvas.
+
image:batch_component.jpg[Batch component on canvas]
. Similar to what was done in step 1, search for *File*.
. Drag *File* into the *Input* section of the batch element created earlier.
. Search for *Message Enricher*, then drag and drop it after *File*.
. Search for *DataMapper* and drag it after *Message Enricher*.
. Search for *Salesforce Analytics Cloud* and drag it into *Message Enricher*.
. Search for *Batch commit* and drag it into the *Batch step* section of *Batch*.
. Search for *Salesforce Analytics Cloud* and drag it into the *Batch commit* section of *Batch step*.
. Drag another *Salesforce Analytics Cloud* connector into the *On complete* section of *Batch*.
. After completing all the above steps you should see:
+
image:batch_flow_unconfigured.png[Unconfigured Batch flow]
. Lets start configuring each element. Double click on the *File* element.
+
image:file_component.jpg[File component]
. Click on `...` next to the *Path* field.
. Choose a folder with only the csv file that you want to upload. You can download our example file and save it into your chosen folder.
+
link:_attachments/CsvDemoTestData.csv[CsvDemoTestData.csv]
. Double-click on the *Salesforce Analytics Cloud* connector in the *Message Enricher*.
. Click on the plus sign next to the *Connector configuration* dropdown.
+
image:create_data_set_config.jpg[Create data set config]
. A pop-up asking for type of configuration appears. Choose the *Salesforce Analytics Cloud: Basic Authentication* option and click *OK*.
. A new pop-up asks for information required for basic authentication. For more info see the <<Installing and Configuring, Installing and Configuring>> section
+
image:basic_authentication_config.png[Basic Auth config]
. In the *Connection* section enter the credentials used to access the Salesforce instance.
. In the *DataSense metadata* section for the *Metadata file name* field enter the filename that describes the data structure you are going to upload. The filename has to be relative to the *src/main/resources* directory of your Studio project. For the file provided a few steps earlier (CsvDemoTestData.csv) you can use the metadata file provided below, but do not forget to copy it into the *src/main/resources* directory.
+
link:_attachments/metadata.json[metadata.json]
. Click *OK* to return to the Salesforce Analytics Cloud tab.
. From the *Operation* dropdown in the *Basic Settings* section choose *Create data set*.
. From the *Operation* dropdown in the *DataSet info* section choose *OVERWRITE*.
. In the *Description* field enter *Test data set*.
. In the *Label* field under *DataSet info* enter *Test data set*.
. In the *Name* field under *DataSet info* enter *test_data_set*.
. Double-click on *Message Enricher* and fill in the fields as below.
+
image:message_enricher_config.jpg[Message Enricher Config]
. Double-click on *Batch commit* from *Batch step*.
. For *Commit size* enter the number of records you want to process in one step. (e.g. 5000)
+
[NOTE]
The application is logging a warning message if the data provided for processing in one step exceeds the size of data accepted by Analytics Cloud System in one step. The message looks like this: "The size of data provided for processing in one step exceeded the maximum size of one chunk allowed by Analytics Cloud System. In order to optimize the memory used you should decrease the size of data provided in one step.". If you see this message then you should tune the *Commit Size* by decreasing it until you do not see the message anymore.
+
. Double-click on *Salesforce Analytics Cloud* from *Batch commit*.
. From the *Connector configuration* dropdown choose *Salesforce_Analytics_Cloud__Basic_authentication* (only this option should be available).
. Choose *Upload external data* as the operation.
. Check the bottom corner on the right-hand side and wait for DataSense to fetch metadata.
+
image:fetch_metadata_bar.jpg[Fetch metadata progress bar]
. For *Data Set Id* enter *#[variable:dataSetId]*
. Double-click on the *DataMapper* element.
. Click on the *Type* dropdown in the Input section and choose *CSV*
. Click on `...` next to the *CSV* field of the Input section and browse to the csv file in the same folder you selected for the *File* connector.
. Click the *Create mapping* button and you should see something like the following.
+
image:DM_mappings.png[Data mapper mappings]
. Double-click on *Salesforce Analytics Cloud* from the *On complete* section of *Batch*.
. From the *Connector configuration* dropdown select *Salesforce_Analytics_Cloud__Basic_authentication* (only this option should be available).
. From the *Operation* dropdown select *Start data processing*.
. In the *Data Set Id* field enter `#[variable:dataSetId]`
. At this point, everything should be set up and the application can be deployed.

It is time to test the application. Run the application in Anypoint Studio (Right click on the project name in Studio's package explorer and select *Run as -> Mule Application*). Monitor the studio console and check Salesforce Wave Analytics UI to see if the data was uploaded.
....
[tab,title="XML Editor"]
....

=== Example Use Case 1

. Add the sfdc-analytics namespace to the mule element as follows:

+

[source,xml,linenums]
----
xmlns:sfdc-analytics="http://www.mulesoft.org/schema/mule/sfdc-analytics"
----

. Add the location of the analytics schema referred to by the sfdc-analytics namespace:

+

[source,xml,linenums]
----
http://www.mulesoft.org/schema/mule/sfdc-analytics http://www.mulesoft.org/schema/mule/sfdc-analytics/current/mule-sfdc-analytics.xsd
----

. Add the data-mapper namespace as follows:

+

[source,xml,linenums]
----
xmlns:data-mapper="http://www.mulesoft.org/schema/mule/ee/data-mapper"
----

. Add location of data mapper schema referred by data-mapper namespace with the following value:

+

[source,xml,linenums]
----
http://www.mulesoft.org/schema/mule/ee/data-mapper http://www.mulesoft.org/schema/mule/ee/data-mapper/current/mule-data-mapper.xsd
----

. Add a context:property-placeholder element to your project, then configure its attributes as follows:

+

[source,xml]
----
<context:property-placeholder location="mule-app.properties"/>
----

. Add a data-mapper:config element to your project, then configure its attributes as follows:

+

[source,xml,linenums]
----
<data-mapper:config name="CSV_To_List_Record_" transformationGraphPath="csv_to_list_record_.grf" doc:name="CSV_To_List_Record_"/>
----

. Add a sfdc-analytics:config element to your project, then configure its attributes as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:config name="Salesforce_Analytics_Cloud__Basic_authentication" username="${salesforce.username}" password="${salesforce.password}" securityToken="${salesforce.securityToken}" metadataFileName="${metadata.file.analytics}" doc:name="Salesforce Analytics Cloud: Basic authentication" url="${salesforce.url}"/>
----

. Add an empty flow element to your project as follows:

+

[source,xml,linenums]
----
<flow name="analytics_performanceFlow">
</flow>
----

. Within the flow element add a file:inbound-endpoint element as follows:

+

[source,xml,linenums]
----
<file:inbound-endpoint path="path_to_folder_to_monitor" moveToDirectory="path_to_folder_where_to_move_processed_files" responseTimeout="10000" doc:name="File">
</file:inbound-endpoint>
----

. Within the flow element add a data-mapper:transform element as follows:

+

[source,xml,linenums]
----
<data-mapper:transform config-ref="CSV_To_List_Record_" doc:name="CSV To List&lt;Record&gt;"/>
----

. Within the flow element add a sfdc-analytics:upload-external-data-into-new-data-set-and-start-processing element as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:upload-external-data-into-new-data-set-and-start-processing config-ref="Salesforce_Analytics_Cloud__Basic_authentication1" type="recordId" operation="UPSERT" description="Test upload of 2500 records all in one step" label="records_2500_in_one_step" dataSetName="records_2500_in_one_step_with_app" edgemartContainer="TestContainer" notificationSent="ALWAYS" notificationEmail="name@email.com" doc:name="Salesforce Analytics Cloud">
    <sfdc-analytics:payload ref="#[payload]"/>
</sfdc-analytics:upload-external-data-into-new-data-set-and-start-processing>
----

. In the end the xml file should look like this:

+

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<mule xmlns:file="http://www.mulesoft.org/schema/mule/file"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
	xmlns:spring="http://www.springframework.org/schema/beans"
	xmlns:sfdc-analytics="http://www.mulesoft.org/schema/mule/sfdc-analytics"
	xmlns:data-mapper="http://www.mulesoft.org/schema/mule/ee/data-mapper"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.mulesoft.org/schema/mule/sfdc-analytics http://www.mulesoft.org/schema/mule/sfdc-analytics/current/mule-sfdc-analytics.xsd
http://www.mulesoft.org/schema/mule/file http://www.mulesoft.org/schema/mule/file/current/mule-file.xsd
http://www.mulesoft.org/schema/mule/ee/data-mapper http://www.mulesoft.org/schema/mule/ee/data-mapper/current/mule-data-mapper.xsd
http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-current.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd">
	<context:property-placeholder location="mule-app.properties"/>
	<sfdc-analytics:config name="Salesforce_Analytics_Cloud__Basic_authentication" username="${salesforce.username}" password="${salesforce.password}" securityToken="${salesforce.securityToken}" metadataFileName="${metadata.file.analytics}" doc:name="Salesforce Analytics Cloud: Basic authentication" url="${salesforce.url}"/>
	<data-mapper:config name="CSV_To_List_Record_" transformationGraphPath="csv_to_list_record_.grf" doc:name="CSV_To_List_Record_"/>
	<flow name="analytics_performanceFlow">
        <file:inbound-endpoint path="path_to_folder_to_monitor" moveToDirectory="path_to_folder_where_to_move_processed_files" responseTimeout="10000" doc:name="File">
        </file:inbound-endpoint>
        <data-mapper:transform config-ref="CSV_To_List_Record_" doc:name="CSV To List&lt;Record&gt;"/>
        <sfdc-analytics:upload-external-data-into-new-data-set-and-start-processing config-ref="Salesforce_Analytics_Cloud__Basic_authentication" type="recordId" operation="UPSERT" description="Test upload of 2500 records all in one step" label="records_2500_in_one_step" dataSetName="records_2500_in_one_step_with_app" edgemartContainer="TestContainer" notificationSent="ALWAYS" notificationEmail="name@email.com" doc:name="Salesforce Analytics Cloud">
            <sfdc-analytics:payload ref="#[payload]"/>
        </sfdc-analytics:upload-external-data-into-new-data-set-and-start-processing>
    </flow>
</mule>
----

==== Example Use Case 2

Create a dataset and upload data into it by processing the data in several chunks.

. Add sfdc-analytics namespace to mule element as follows:

+

[source,xml,linenums]
----
xmlns:sfdc-analytics="http://www.mulesoft.org/schema/mule/sfdc-analytics"
----

. Add location of analytics schema referred by sfdc-analytics namespace with the following value:

+

[source,xml,linenums]
----
http://www.mulesoft.org/schema/mule/sfdc-analytics http://www.mulesoft.org/schema/mule/sfdc-analytics/current/mule-sfdc-analytics.xsd
----

. Add data-mapper namespace as follows:

+

[source,xml]
----
xmlns:data-mapper="http://www.mulesoft.org/schema/mule/ee/data-mapper"
----

. Add location of data mapper schema referred by data-mapper namespace with the following value:

+

[source,xml,linenums]
----
+http://www.mulesoft.org/schema/mule/ee/data-mapper+ +http://www.mulesoft.org/schema/mule/ee/data-mapper/current/mule-data-mapper.xsd+
----

. Add a context:property-placeholder element to your project, then configure its attributes as follows:

+

[source,xml]
----
<context:property-placeholder location="mule-app.properties"/>
----

. Add a data-mapper:config element to your project, then configure its attributes as follows:

+

[source,xml,linenums]
----
<data-mapper:config name="CSV_To_List_Record_" transformationGraphPath="csv_to_list_record_.grf" doc:name="CSV_To_List_Record_"/>
----

. Add a sfdc-analytics:config element to your project, then configure its attributes as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:config name="Salesforce_Analytics_Cloud__Basic_authentication" username="${salesforce.username}" password="${salesforce.password}" securityToken="${salesforce.securityToken}" metadataFileName="${metadata.file.analytics}" doc:name="Salesforce Analytics Cloud: Basic authentication" url="${salesforce.url}"/>
----

. Add an empty batch:job element to your project as follows:

+

[source,xml,linenums]
----
<batch:job name="demoBatch">
    <batch:input>
    </batch:input>
    <batch:process-records>
    </batch:process-records>
    <batch:on-complete>
    </batch:on-complete>
</batch:job>
----

. Add a file:inbound-endpoint element into batch:input of batch:job, then configure it as follows:

+

[source,xml,linenums]
----
<file:inbound-endpoint path="path_to_folder_to_monitor" moveToDirectory="path_to_folder_where_to_move_processed_files" responseTimeout="10000"
                       doc:name="File For Batch">
</file:inbound-endpoint>
----

. Add an empty enricher element into batch:input of batch:job, then configure it as follows:

+

[source,xml,linenums]
----
<enricher source="#[payload]" target="#[variable:dataSetId]" doc:name="Message Enricher">
</enricher>
----

. Add a sfdc-analytics:create-data-set element into enricher, then configure it as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:create-data-set config-ref="Salesforce_Analytics_Cloud__Basic_authentication" operation="OVERWRITE" description="${batch.dataSetDescription}" label="${batch.dataSetLabel}" dataSetName="${batch.dataSetName}" edgemartContainer="${batch.dataSetEdgemartContainer}" notificationSent="ALWAYS" notificationEmail="name@email.com" doc:name="Salesforce Analytics Cloud"/>
----

. Add a data-mapper:transform element into batch:input of batch:job, then configure it as follows:

+

[source,xml,linenums]
----
<data-mapper:transform config-ref="CSV_To_List_Record_" doc:name="CSV To List&lt;Record&gt;"/>
----

. Add an empty batch:step element into batch:process-records of batch:job, then configure it as follows:

+

[source,xml,linenums]
----
<batch:step name="Batch_Step">
</batch:step>
----

. Add an empty batch:commit element into batch:step of batch:process-records, then configure it as follows:

+

[source,xml,linenums]
----
<batch:commit  doc:name="Batch Commit" size="3000">
</batch:commit>
----

. Add a sfdc-analytics:upload-external-data element into batch:commit of batch:step of batch:process-records, then configure it as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:upload-external-data config-ref="Salesforce_Analytics_Cloud__Basic_authentication" type="recordId" dataSetId="#[variable:dataSetId]" doc:name="Salesforce Analytics Cloud">
    <sfdc-analytics:payload ref="#[payload]"/>
</sfdc-analytics:upload-external-data>
----

. Add a sfdc-analytics:start-data-processing element into batch:on-complete of batch:job, then configure it as follows:

+

[source,xml,linenums]
----
<sfdc-analytics:start-data-processing config-ref="Salesforce_Analytics_Cloud__Basic_authentication" dataSetId="#[variable:dataSetId]" doc:name="Salesforce Analytics Cloud"/>
----

. In the end the xml file should look like this:

+

[source,xml,linenums]
----
<?xml version="1.0" encoding="UTF-8"?>
<mule xmlns:batch="http://www.mulesoft.org/schema/mule/batch"
	xmlns:file="http://www.mulesoft.org/schema/mule/file"
	xmlns:context="http://www.springframework.org/schema/context"
	xmlns="http://www.mulesoft.org/schema/mule/core" xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
	xmlns:spring="http://www.springframework.org/schema/beans"
	xmlns:sfdc-analytics="http://www.mulesoft.org/schema/mule/sfdc-analytics"
	xmlns:data-mapper="http://www.mulesoft.org/schema/mule/ee/data-mapper"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="
http://www.mulesoft.org/schema/mule/batch http://www.mulesoft.org/schema/mule/batch/current/mule-batch.xsd
http://www.mulesoft.org/schema/mule/sfdc-analytics http://www.mulesoft.org/schema/mule/sfdc-analytics/current/mule-sfdc-analytics.xsd
http://www.mulesoft.org/schema/mule/file http://www.mulesoft.org/schema/mule/file/current/mule-file.xsd
http://www.mulesoft.org/schema/mule/ee/data-mapper http://www.mulesoft.org/schema/mule/ee/data-mapper/current/mule-data-mapper.xsd
http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-current.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd">
	<context:property-placeholder location="mule-app.properties"/>
	<sfdc-analytics:config name="Salesforce_Analytics_Cloud__Basic_authentication" username="${salesforce.username}" password="${salesforce.password}" securityToken="${salesforce.securityToken}" metadataFileName="${metadata.file.analytics}" doc:name="Salesforce Analytics Cloud: Basic authentication" url="${salesforce.url}"/>
	<data-mapper:config name="CSV_To_List_Record_" transformationGraphPath="csv_to_list_record_.grf" doc:name="CSV_To_List_Record_"/>
	<batch:job name="demoBatch">
        <batch:input>
            <file:inbound-endpoint path="path_to_folder_to_monitor" moveToDirectory="path_to_folder_where_to_move_processed_files" responseTimeout="10000"
                                   doc:name="File For Batch">
            </file:inbound-endpoint>
            <enricher source="#[payload]" target="#[variable:dataSetId]" doc:name="Message Enricher">
                <sfdc-analytics:create-data-set config-ref="Salesforce_Analytics_Cloud__Basic_authentication" operation="OVERWRITE" description="${batch.dataSetDescription}" label="${batch.dataSetLabel}" dataSetName="${batch.dataSetName}" edgemartContainer="${batch.dataSetEdgemartContainer}" notificationSent="ALWAYS" notificationEmail="name@email.com" doc:name="Salesforce Analytics Cloud"/>
            </enricher>
            <data-mapper:transform config-ref="CSV_To_List_Record_" doc:name="CSV To List&lt;Record&gt;"/>
        </batch:input>
        <batch:process-records>
            <batch:step name="Batch_Step">
                <batch:commit  doc:name="Batch Commit" size="3000">
                    <sfdc-analytics:upload-external-data config-ref="Salesforce_Analytics_Cloud__Basic_authentication" type="recordId" dataSetId="#[variable:dataSetId]" doc:name="Salesforce Analytics Cloud">
                        <sfdc-analytics:payload ref="#[payload]"/>
                    </sfdc-analytics:upload-external-data>
                </batch:commit>
            </batch:step>
        </batch:process-records>
        <batch:on-complete>
            <sfdc-analytics:start-data-processing config-ref="Salesforce_Analytics_Cloud__Basic_authentication" dataSetId="#[variable:dataSetId]" doc:name="Salesforce Analytics Cloud"/>
        </batch:on-complete>
    </batch:job>
</mule>
----
....
------


== 另请参阅

* 了解 link:/mule-user-guide/v/3.8/batch-processing[批量处理]。
* 详细了解 link:/mule-user-guide/v/3.8/anypoint-connectors[Anypoint连接器]。
