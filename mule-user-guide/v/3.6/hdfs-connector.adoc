=  HDFS连接器
:keywords: anypoint studio, esb, connectors, hdfs

社区

Hadoop分布式文件系统（HDFS）的Anypoint连接器用作Mule应用程序和Apache Hadoop实例之间的双向网关。

== 先决条件

要使用HDFS连接器，您必须具备以下条件：

*   正在运行的Apache Hadoop服务器。
*    Anypoint Studio社区版。

本文档假定您熟悉Mule， link:/mule-user-guide/v/3.6/anypoint-connectors[Anypoint连接器]和 link:/anypoint-studio/v/6/index[Anypoint Studio Essentials]。为提高您对Studio的熟悉度，请考虑完成一个或多个 link:/anypoint-studio/v/6/basic-studio-tutorial[Anypoint Studio教程]。此外，本页假定您对 link:/mule-user-guide/v/3.6/mule-concepts[骡流]和 link:/mule-user-guide/v/3.6/global-elements[骡全球元素]有基本的了解。

本文档描述了Anypoint Studio（Mule ESB的图形用户界面）上下文中的实现示例，还包括在XML编辑器中执行相同操作的配置详细信息。

== 兼容性

HDFS Hadoop连接器与以下设备兼容：

[%header,cols="2*"]
|===
一个|
应用程序/服务

 为|
版

| Mule运行时间 | 3.6或更高
| Apache Hadoop  | 2.6.0或更高版本
|===

== 安装和配置

=== 在Anypoint Studio中安装HDFS连接器

您可以使用 link:/mule-user-guide/v/3.6/installing-connectors[从Anypoint Exchange安装连接器]中的说明在Anypoint Studio中安装连接器。


=== 配置全局元素

要在Mule应用程序中使用HDFS连接器，您必须配置一个全局HDFS元素，该应用程序中的所有HDFS连接器都可以使用该元素。

. 在Anypoint Studio中，点击画布底部的*Global Elements*标签，然后点击*Create*。
. 在*Choose Global Type*向导中，使用过滤器定位并选择*HDFS*，然后单击*OK*。
. 根据下表配置参数。
+
[%header%autowidth.spread]
|===
| {参数{1}}说明
| *Name*  |为稍后可以引用的配置输入一个名称。
| *NameNode URI*  |输入Hadoop集群主节点的主机名或IP地址。
| *Username*  |输入Hadoop文件系统用户名。
| *Configuration Resources*  |如果您想覆盖Hadoop实例的配置资源，请从此处选择合适的选项。
| *Configuration Entries*  |如果您想覆盖Hadoop实例的配置条目，请从此处选择合适的选项。
|===
+
. 访问*Pooling Profile*标签，配置与使用连接池管理多个连接相关的任何设置。
. 访问*Reconnection*选项卡，配置与Mule在丢失其与HDFS的连接时应执行的重新连接策略相关的任何设置。
. 点击*Test Connection*以接收_Connection Successful_消息。
. 点击*OK*保存全局连接器配置。
. 返回到Studio中的消息流选项卡。

=== 使用XML编辑器进行配置


确保您已将HDFS名称空间包含在配置文件中。

[source,xml, linenums]
----
<mule xmlns:mulexml="http://www.mulesoft.org/schema/mule/xml" xmlns:hdfs="http://www.mulesoft.org/schema/mule/hdfs"
      xmlns:http="http://www.mulesoft.org/schema/mule/http"
      xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
      xmlns:spring="http://www.springframework.org/schema/beans"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.mulesoft.org/schema/mule/core" xsi:schemaLocation="http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
http://www.mulesoft.org/schema/mule/hdfs http://www.mulesoft.org/schema/mule/hdfs/current/mule-hdfs.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/xml http://www.mulesoft.org/schema/mule/xml/current/mule-xml.xsd">
----

请按照以下步骤在应用程序中配置HDFS连接器：

. 使用以下全局配置代码在流的外部和上方创建全局HDFS配置。
+
[source,xml, linenums]
----
<!-- Simple configuration -->
<hdfs:config nameNodeUri="${mule.HDFS.nameNodeUri}" username="${mule.HDFS.username}"/>
----

[%header%autowidth.spread]
|===
| {参数{1}}说明
| _ Name _  |输入配置的名称，稍后可由config-ref引用该名称。此示例中的名称是`hdfs:config`。
| *nameNode Uri*  |输入Hadoop集群主节点的主机名或IP地址。
| *username*  |输入Hadoop FileSystem用户名。
|===



== 使用连接器

HDFS连接器是基于操作的连接器，这意味着将连接器添加到流中时，需要配置连接器执行的特定操作。 HDFS连接器当前支持以下操作列表：

[%header,cols="34,33,33"]
|===
|操作 | XML元素 |描述
| *Append to File*  | <hdfs:append>  |将当前有效内容附加到位于指定路径的文件。
| *Copy from Local File*  | <hdfs:copy-from-local-file>  |将本地磁盘上的源文件复制到给定目标路径上的FileSystem。如果应删除源，请设置deleteSource。
| *Copy to Local File*  | <hdfs:copy-to-local-file>  |将文件系统上的源文件复制到给定目标路径的本地磁盘上。如果应删除源，请设置deleteSource。
| *Delete Directories*  | <hdfs:delete-directory>  |删除位于指定路径的文件或目录。
| *Delete File*  | <hdfs:delete-file>  |删除位于指定路径的文件或目录。
| *Get Path Meta Data*  | <hdfs:get-metadata>  |获取路径的元数据并将其存储在流变量中。
| *Glob Status*  | <hdfs:glob-status>  |返回所有匹配文件模式的文件，不是校验和文件。
| *List Status*  | <hdfs:list-status>  |如果路径是目录，列出给定路径中文件和目录的状态。
| *Make Directories*  | <hdfs:make-directories>  |使文件和所有不存在的父目录进入目录。
| *Read from Path*  | <hdfs:read>  |读取由其路径指定的文件的内容，并将内容流式传输到其余的流。还要将HDFS_PATH_EXISTS和HDFS_CONTENT_SUMMARY入站属性添加到路径元数据中。
| *Rename*  | <hdfs:rename>  |将路径目标重命名为路径目标。
| *Set Owner*  | <hdfs:set-owner>  |设置路径的所有者，路径可以是文件或目录的路径。
| *Set Permission*  | <hdfs:set-permission>  |设置路径的权限，路径可以是文件或目录的路径。
| *Write to Path*  | <hdfs:write>  |将当前有效负载写入指定路径，创建新文件或附加到现有文件。
|===

=== 将连接器添加到Mule流中

. 创建一个新的Anypoint Studio项目。
. 添加任何Mule入站端点，例如HTTP侦听器，以开始。 +
. 将HDFS连接器拖到画布上，然后选择它以打开属性编辑器控制台。
. 根据下表配置连接器的参数。
+
[%header,cols="34,33,33"]
|===
| {字段{1}}说明 |缺省
| *Display Name*  |为应用程序中的连接器输入唯一标签。 | HDFS
| *Connector Configuration*  |连接到链接到此连接器的全局元素。全局元素封装有关到目标资源或服务的连接的可重用数据。选择您刚创建的全局HDFS连接器元素。 | 
| *Operation*  |选择此组件必须执行的操作。 | 
|===
. 保存您的配置。

== 用例

以下是HDFS连接器的两种常见用例：+

* 使用Mule应用程序在Apache Hadoop实例中创建文件。
* 使用Mule应用程序从Apache Hadoop实例中删除文件。

=== 示例：使用案例1

使用Mule应用程序在Hadoop实例中创建文件：

image:hdfsflow.png[hdfsflow]

. 在Anypoint Studio中，将HTTP连接器拖动到画布上，然后选择它以打开属性编辑器控制台。
. 添加新的HTTP侦听器配置全局元素：
.. 在*General Settings*中，点击*Add*按钮：
+
image:4-1.png[4-1]
.. 配置以下HTTP参数：
+
image:5-1.png[5-1]
+
[%header,cols="2*"]
|===
一个|
领域

 为|
值

| *Port*  | 8090
| *Path*  | filecreate
| *Host*  |本地主机
| *Display Name*  | HTTP_Listener_Configuration
|===

. 引用HTTP侦听器配置全局元素：
+
image:6-1.png[6-1]

. 添加记录器作用域以打印需要在Mule控制台中创建的文件的名称。根据下表配置记录器。
+
[%header%autowidth.spread]
|===
| {字段{1}}值
| *Display Name*  |写入路径日志（或您喜欢的任何其他名称）
| *Message*  |创建文件：`#[message.inboundProperties['http.query.params'].path] with message: #[message.inboundProperties['http.query.params`']。msg]
| *Level*  |信息（默认）
|===

. 添加一个设置负载转换器，将消息输入设置为有效负载，并根据下表进行配置。
+
[%header%autowidth.spread]
|===
| {字段{1}}值
| *Display Name*  |将消息输入设置为有效负载（或您喜欢的任何其他名称）
| *Value*  | `#[message.inboundProperties['http.query.params`“。MSG]
|===
. 将HDFS连接器拖到画布上，并选择它以打开属性编辑器控制台。
. 点击*Connector Configuration*字段旁边的加号，添加新的全局连接器配置。
. 根据下表配置全局元素。
+
[%header%autowidth.spread]
|===
| {字段{1}}值
| {名称{1}} HDFS
| NameNode URI  | <NameNode URI of Hadoop instance>
|用户名 | <Your Hadoop FileSystem username>
|===
. 返回应用程序中HDFS连接器的属性编辑器，根据下表配置其余参数。
+
[%header%autowidth.spread]
|====
| {字段{1}}值
| *Display Name*  |写入路径（或您喜欢的任何其他名称）
| *Connector* *Configuration*  | hdfs-conf（您创建的全局元素的名称）
| *Operation*  |写入路径
| *Path*  | `#[message.inboundProperties['http.query.params'].path]`
|====

. 将项目作为Mule应用程序运行（右键单击项目名称并单击**Run As > Mule Application**）。
. 从浏览器中导航到`http://localhost:8090/path=filecreate`
.  Mule执行查询，并使用指定的消息在Hadoop中创建文件。

===  XML编辑器


image:hdfsflow.png[hdfsflow]

. 为您的项目添加一个`hdfs:config`全局元素，并根据下表配置其属性。
+
[source,xml, linenums]
----
<hdfs:config name="HDFS" doc:name="HDFS" username="<username>" nameNodeUri="<namenode" />
----
+
[%header%autowidth.spread]
|=======
| {属性{1}}值
| *name*  | HDFS
| *doc:name*  | HDFS
| *username*  | <Your Hadoop FileSystem username>
| *nameNodeUri*  | NameNode Hadoop实例的URI
|=======

. 添加一个http：listner-config元素，如下所示。
+
[source,xml, linenums]
----
<http:listener-config name="HTTP_Listener_Configuration" host="localhost" port="8090" basePath="filecreate" doc:name="HTTP Listener Configuration"/>
<http:connector name="HTTP_HTTPS" cookieSpec="netscape" validateConnections="true" sendBufferSize="0" receiveBufferSize="0" receiveBacklog="0" clientSoTimeout="10000" serverSoTimeout="10000" socketSoLinger="0" doc:name="HTTP-HTTPS"/>
----
+
[%header,cols="2*"]
|===
| {属性{1}}值
| *name*  | HTTP_Listener_Configuration
| *host*  |本地主机
| *port*  | 8090
| *basePath*  | filecreate
| *doc:name*  | HTTP侦听器配置
|===

. 使用http：listener开始流程。
+
[source,xml, linenums]
----
<http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/>
----
+
[%header%autowidth.spread]
|===
| {属性{1}}值
| *config-ref*  | HTTP_Listener_Configuration
| *Path*  | /
| *doc:name*  | HTTP
|===

. 为您的流程添加Logger转换器，根据下表配置属性。
+
[source,xml, linenums]
----
<set-payload value="#[message.inboundProperties['http.query.params'].msg]" doc:name="Set the message input as payload"/>
----
+
[%header,cols="2*"]
|====
| {属性{1}}值
| *message* a |
----

Creating file: #[message.inboundProperties['http.query.params'].path]
----

----

with message: #[message.inboundProperties['http.query.params'].msg]
----


| *level*  |信息（默认）
| *doc:name*  |写入路径日志
|====
+
. 添加一个设置负载转换器，将消息输入设置为有效负载。
+
[source,xml, linenums]
----
<set-payload value="#[message.inboundProperties['http.query.params'].msg]" doc:name="Set the message input as payload"/>
----
+
[%header%autowidth.spread]
|======
| {属性{1}}值
| *Value*  | `#[message.inboundProperties['http.query.params'].msg]`
| *doc:name*  |将消息输入设置为有效内容
|======
. 为您的流添加一个`hdfs:write`元素，并根据下表配置属性。
+
[%header%autowidth.spread]
|======
| {属性{1}}值
| *config-ref*  | HDFS-conf的
| *doc:name*  |写入路径
| *path*  | `#[message.inboundProperties['http.query.params'].path]`
|======

. 将项目作为Mule应用程序运行（右键单击项目名称并单击*Run As*> *Mule Application*）。
. 从浏览器中导航到`http://localhost:8090/path=filecreate`
.  Mule执行查询，并使用指定的消息在Hadoop中创建文件。


=== 示例代码

[source,xml, linenums]
----
<mule xmlns:tracking="http://www.mulesoft.org/schema/mule/ee/tracking" xmlns:mulexml="http://www.mulesoft.org/schema/mule/xml" xmlns:hdfs="http://www.mulesoft.org/schema/mule/hdfs"
      xmlns:http="http://www.mulesoft.org/schema/mule/http"
      xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
      xmlns:spring="http://www.springframework.org/schema/beans"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.mulesoft.org/schema/mule/core" xsi:schemaLocation="http://www.mulesoft.org/schema/mule/http http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
http://www.mulesoft.org/schema/mule/hdfs http://www.mulesoft.org/schema/mule/hdfs/current/mule-hdfs.xsd
http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/xml http://www.mulesoft.org/schema/mule/xml/current/mule-xml.xsd
http://www.mulesoft.org/schema/mule/ee/tracking http://www.mulesoft.org/schema/mule/ee/tracking/current/mule-tracking-ee.xsd">
<hdfs:config name="hdfs-conf" nameNodeUri="<Name node URI>" username="<FileSystem Username>" doc:name="HDFS"/>
<http:listener-config name="HTTP_Listener_Configuration" host="localhost" port="8090" basePath="filecreate" doc:name="HTTP Listener Configuration"/>
<http:connector name="HTTP_HTTPS" cookieSpec="netscape" validateConnections="true" sendBufferSize="0" receiveBufferSize="0" receiveBacklog="0" clientSoTimeout="10000" serverSoTimeout="10000" socketSoLinger="0" doc:name="HTTP-HTTPS"/>
<flow name="Create_File_Flow" doc:name="Create_File_Flow">
<http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/>
<logger message="Creating file: #[message.inboundProperties['http.query.params'].path] with message: #[message.inboundProperties['http.query.params'].msg]" level="INFO" doc:name="Write to Path Log"/>
<set-payload value="#[message.inboundProperties['http.query.params'].msg]" doc:name="Set the message input as payload"/>
<hdfs:write config-ref="hdfs-conf" path="#[message.inboundProperties['http.query.params'].path]" doc:name="Write to Path"/>
</flow>
</mule>
----

=== 示例：使用案例2

使用Mule应用程序从Hadoop实例中删除文件：

image:DeleteFileFlow.png[DeleteFileFlow]

. 将HTTP连接器拖到画布中，然后选择它以打开属性编辑器控制台。
. 添加新的HTTP侦听器配置全局元素：
.. 在*General Settings*中，点击*Add*按钮：
+
image:11-1.png[11-1]
.. 配置以下HTTP参数：
+
image:12-1.png[12-1]
+
[%header,cols="2*"]
|===
一个|
领域

 为|
值

| *Port*  | 8090
| *Path*  | filedelete
| *Host*  |本地主机
| *Display Name*  | HTTP_Listener_Configuration
|===

.  引用HTTP侦听器配置全局元素：
+
image:13.png[13] +

. 在HTTP端点之后添加一个Logger作用域，以在Mule控制台中打印需要删除的文件的名称。根据下表配置记录器。
+
[%header%autowidth.spread]
|====
| {字段{1}}值
| *Display Name*  |删除文件日志（或您喜欢的任何其他名称）
| *Message*  |删除文件：`#[message.inboundProperties['http.query.params'].path]`
| *Level*  |信息（默认）
|====
. 将HDFS连接器拖到画布上，然后单击它以打开属性编辑器控制台。
. 单击“连接器配置”字段旁边的加号以添加新的全局连接器配置。
. 根据下表配置全局元素。
+
[%header%autowidth.spread]
|===
| {字段{1}}值
| {名称{1}} HDFS
| NameNode URI  | <NameNode URI of Hadoop instance>
|用户名 | <Your Hadoop FileSystem username>
|===
. 返回应用程序中HDFS连接器的属性编辑器，根据下表配置其余参数。
+
[%header%autowidth.spread]
|====
| {字段{1}}值
| *Display Name*  |删除文件（或您喜欢的任何其他名称）
| *Connector* *Configuration*  | hdfs-conf（您创建的全局元素的名称）
| *Operation*  |删除文件
| *Path*  | `#[ message.inboundProperties['http.query.params'].path]`
|====

. 将项目作为Mule应用程序运行（右键单击项目名称，然后单击**Run As > Mule Application**）。
. 从浏览器中导航到`  http://localhost:8090/path= filedelete`
.  Mule执行查询，并从Hadoop中删除文件。

===  XML编辑器

image:hdfsflow.png[hdfsflow]

. 为您的项目添加一个`hdfs:config`全局元素，然后根据下表配置其属性。
+
[source,xml, linenums]
----
<hdfs:config name="HDFS" doc:name="HDFS" username="<username>" nameNodeUri="<namenode" />
----
+
[%header%autowidth.spread]
|=======
| {属性{1}}值
| *name*  | HDFS
| *doc:name*  | HDFS
| *username*  | <Your Hadoop FileSystem username>
| *nameNodeUri*  | NameNode Hadoop实例的URI
|=======

. 添加一个`http:listener-config`元素，如下所示：
+
[source,xml, linenums]
----
<http:listener-config name="HTTP_Listener_Configuration" host="localhost" port="8090" basePath="filedelete" doc:name="HTTP Listener Configuration"/>
<http:connector name="HTTP_HTTPS" cookieSpec="netscape" validateConnections="true" sendBufferSize="0" receiveBufferSize="0" receiveBacklog="0" clientSoTimeout="10000" serverSoTimeout="10000" socketSoLinger="0" doc:name="HTTP-HTTPS"/>
----
+
[%header%autowidth.spread]
|====
| {属性{1}}值
| *name*  | HTTP_Listener_Configuration
| *host*  | 0.0.0.0
| *port*  | 8090
| *basePath*  | filedelete
|====

. 使用http：listener开始流程。
+
[source,xml, linenums]
----
<http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/>
----
+
. 为您的流程添加Logger转换器，根据下表配置属性。
+
[source,xml, linenums]
----
<logger message="Deleting file:
#[message.inboundProperties['http.query.params'].path]" level="INFO"
doc:name="Delete file log"/>
----
+
[%header%autowidth.spread]
|===
| {属性{1}}值
| *message*  |删除文件：＃` [message.inboundProperties['http.query.params'].path]`
| *level*  |信息（默认）
| *doc:name*  |删除文件日志
|===
. 为您的流程添加一个`hdfs:delete-file`元素，并根据下表配置属性。
+
[source,xml, linenums]
----
<hdfs:delete-file config-ref="hdfs-conf" doc:name="Delete
file" path="#[message.inboundProperties['http.query.params'].path]"/>
----
+
[%header%autowidth.spread]
|=======
| {属性{1}}值
| *config-ref*  | HDFS-conf的
| *doc:name*  |删除文件
| *path*  | `# [message.inboundProperties['http.query.params'].path]`
|=======
. 将项目作为Mule应用程序运行（右键单击项目名称，然后选择Run As> Mule Application）。
. 从浏览器中导航到` http://localhost:8090/path= ` `filedelete`
.  Mule执行查询，并从Hadoop中删除文件。


=== 示例代码

[source,xml, linenums]
----
<mule xmlns:tracking="http://www.mulesoft.org/schema/mule/ee/tracking"
xmlns:mulexml="http://www.mulesoft.org/schema/mule/xml"
xmlns:hdfs="http://www.mulesoft.org/schema/mule/hdfs"
xmlns:http="http://www.mulesoft.org/schema/mule/http"
xmlns:doc="http://www.mulesoft.org/schema/mule/documentation"
xmlns:spring="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns="http://www.mulesoft.org/schema/mule/core"
xsi:schemaLocation="http://www.mulesoft.org/schema/mule/http
http://www.mulesoft.org/schema/mule/http/current/mule-http.xsd
http://www.mulesoft.org/schema/mule/hdfs
http://www.mulesoft.org/schema/mule/hdfs/current/mule-hdfs.xsd
http://www.springframework.org/schema/beans
http://www.springframework.org/schema/beans/spring-beans-current.xsd
http://www.mulesoft.org/schema/mule/core
http://www.mulesoft.org/schema/mule/core/current/mule.xsd
http://www.mulesoft.org/schema/mule/xml
http://www.mulesoft.org/schema/mule/xml/current/mule-xml.xsd
http://www.mulesoft.org/schema/mule/ee/tracking
http://www.mulesoft.org/schema/mule/ee/tracking/current/mule-tracking-ee.xsd
">
<hdfs:config name="hdfs-conf" nameNodeUri="<Name node URI>" username="
<FileSystem Username>" doc:name="HDFS"/>
<http:listener-config name="HTTP_Listener_Configuration" host="localhost" port="8090" basePath="filecreate" doc:name="HTTP Listener Configuration"/>
<http:connector name="HTTP_HTTPS" cookieSpec="netscape" validateConnections="true" sendBufferSize="0" receiveBufferSize="0" receiveBacklog="0" clientSoTimeout="10000" serverSoTimeout="10000" socketSoLinger="0" doc:name="HTTP-HTTPS"/>
<flow name="Delete_File_Flow" doc:name="Delete_File_Flow">
<http:listener config-ref="HTTP_Listener_Configuration" path="/" doc:name="HTTP"/>
<logger message="Deleting file:
#[message.inboundProperties['http.query.params'].path]" level="INFO" 
doc:name="Delete file
log"/>
<hdfs:delete-file config-ref="hdfs-conf" doc:name="Delete file"
path="#[message.inboundProperties['http.query.params'].path]"/>
</flow>
</mule>
----

== 另请参阅

*  link:/release-notes/hdfs-connector-release-notes[HDFS连接器发行说明]
*  link:/mule-user-guide/v/3.6/anypoint-connectors[Anypoint连接器]
*  link:/mule-user-guide/v/3.6/using-maven-with-mule[使用与骡子的Maven]
