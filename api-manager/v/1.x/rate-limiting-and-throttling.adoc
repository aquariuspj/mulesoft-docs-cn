= 限制和速率限制策略参考

深入研究节流和速率限制背后的技术涵盖了与在Mule 3.x及更早版本上部署的API相关的限制和速率限制策略主题。许多参考文献也适用于部署在Mule Runtime 4.x上的API。

== 术语

以下条款适用于速率限制和限制：

* 限制：一系列配对 - 配额，窗口
* 配额：您在API Manager中配置的`# of Reqs`
* 窗口：API管理器对 - 时间段，时间单位
* 重试：限制队列请求的能力
* 合同：应用程序与SLA之间的关系


== 限制

在API管理器中选择限制可为速率限制和限制算法定义_quota_ per _time window_配置。该算法在收到第一个请求时按需创建。此事件修复了时间窗口。

每个请求都会消耗当前窗口的配额，直到时间到期。
当配额用尽时，由此产生的行动取决于政策：

* 速率限制拒绝请求。
* 限制队列请求重试。

当时间窗口关闭时，配额将被重置，并开始一个具有相同固定大小的新窗口。
该策略使用_quota_ per _time window_ configuration为每个限制创建一个算法。因此，如果配置了多个限制，则每个算法都必须在其当前窗口中具有可用配额，以便请求被接受。


== 响应标题

以下访问限制策略返回包含有关请求当前状态信息的标题：

*  X-​​Ratelimit-Remaining：可用配额的数量。
*  X-​​Ratelimit-Limit：每个窗口的最大可用请求数。
*  X-​​Ratelimit-Reset：剩余时间，以毫秒为单位，直到新窗口开始。

== 限制重试次数

由于节流旨在平滑尖峰，Mule运行时可以延迟请求并稍后重试请求。以下示例描述了请求被拒绝或接受的方式。

=== 拒绝了请求

策略配置：5个请求/ 10秒窗口，1个延迟500ms重试

image::throttling-rejected-request.png[]

用户在六秒内发送5个请求，并且全部都被接受。在8秒钟，新的请求进入。没有配额，所以请求延迟500毫秒。

在8.5秒时，排队的请求被重新处理。由于窗户尚未关闭，因此仍然没有配额。此外，没有更多可用重试，因此请求被拒绝。

=== 已接受请求

策略配置：5个请求/ 10秒窗口，1个延迟500ms重试

image::throttling-accepted-request.png[]

用户在前9秒内发送5个请求，全部都被接受。
在9.7秒时，新的请求进入。没有配额，所以请求延迟500毫秒。

10秒钟后，窗口关闭，配额重置为5。
在开始10.2秒（当前窗口的0.2秒标记）之后，排队的请求被重新处理。现在，有可用的配额，因此请求被接受（可用配额减少到4）。

=== 配置

由于Throttling策略在HTTP堆栈上工作，因此必须在用户和API之间为每个要重新处理的排队请求保留一个打开的连接。这个过程是资源密集型的，并且在大窗口中，由于超时，HTTP或底层TCP可能会取消连接。

虽然在Gateway 2.x和Mule Runtime 3.x中没有强制执行，但推荐使用小窗口。一（1）秒的最大窗口被认为很小。建议在独立环境中使用此策略。

== 群集与独立

实现弹性的一种方法是使用冗余：为同一个API提供多个Mule运行时实例。

在这种情况下，考虑是否应该共享速率限制（有或没有SLA）。您可以将Mule运行时设置为在群集中运行以共享配置的限制，并将所有节点视为一个整体。

以下分析涵盖了不同的场景。

=== 分散处理

_n_节点其中：

* 每个都有自己的后端。
* 最快的回复是必需的。
* 提供的请求数量仅受后端容量的限制。
*  SLA级别不可用，或者每个节点仅服务一个。
+
例如，您需要两个节点;一个分配给该公司的计费用户，另一个分配给其余的。

对于这种情况下的分散式处理，不需要集群。只需将策略设置为低于最弱节点的后端容量即可。在没有SLA的情况下，负载平衡器在节点发生故障时可能会有用。

=== 集中处理

_n_节点其中：

* 后端是集中式的。
* 提供的请求数量仅受后端容量的限制。
*  SLA级别不可用，或者每个节点都提供相同的单一SLA。
+
例如，每个节点都被分配给公司的账单用户。

如果前面有负载均衡器，则不需要集群。如果_q_是后端的最大容量，则配置策略如下：

image:quota-policy-formula.png[]

其中 image:omega.png[]是一个小数字，低于后端最大容量。

如果没有负载均衡器，则建议使用独立模式，因为您无法事先配置每个节点将处理多少流量。这些策略旨在兼顾完美均衡的工作负载或完全不均衡。后端不会收到任何额外的请求。

=== 多名工人

_n_ CloudHub工作人员其中：

* 每个代表相同的API。
* 应用程序工作负载在工作人员中平均分配。

该方法应该与_Centralized processing_用例相同。

=== 使用多个合同

_n_节点其中：

SLA被应用。

如果应用速率限制SLA，并且每个节点都必须接受来自多个SLA的请求，则在这种情况下，群集是一个不错的选择，因为您无法事先确定每个节点将服务的每个SLA有多少个请求。

时间窗口在群集中的大小=== 

在群集中，节点必须共享信息以保证整个群集的一致性。共享过程会增加审查性能时必须考虑的延迟。

在最坏的情况下，由于集群一致性而带来延迟的惩罚性请求的数量是恒定的，并且与配置的配额的实际大小无关。因此，窗口越小，潜在延迟请求的百分比就越大。因此，MuleSoft强烈建议在速率限制和速率限制SLA策略配置中设置_only_窗口大小超过一分钟。

=== 最小化延迟

聚集算法最大限度地减少了共享信息的数量以最大限度地提高性能。响应标头（X-Rate-Limit标头）是使用启发式来计算的，它可以预测群集中可用配额的大小，而无需在每个请求上重新同步。标题信息中的错误总是少于10％。但是，接受请求的数量不会超过定义的配额。

=== 配置

在API Gateway Runtime 2.x和Mule Runtime 3.x中，使用和不使用SLA的速率限制策略将自动在集群中运行。您无法关闭此功能。

== 持久性

您可以配置速率限制和限制算法以使用大窗口大小：日，月，年。例如，假设您希望允许您的用户X每年消费1M个请求。您无法预测该节点是整个周期还是需要维护，这可能会导致重新启动运行时。该算法已运行数月，因此客户端将丢失重要信息。持久性通过定期保存当前策略状态来解决此问题。在重新部署或重新启动的情况下，算法将从最后一次已知的持久状态重新创建，或从干净状态开始。

尽管默认情况下启用了持久性，但可以通过将以下属性设置为false来关闭它：

`throttling.persistence_enabled`

您还可以调整持续频率，默认值为10秒：

`throttling.persistent_data_update_freq`

*IMPORTANT:*此功能在CloudHub上禁用。

== 另请参阅

*  link:/api-manager/v/1.x/tutorial-manage-an-api[应用策略和SLA层]
*  link:/api-manager/v/1.x/delete-sla-tier-task[删除SLA层]
*  link:/api-manager/v/1.x/resource-level-policies-about[关于资源级策略]




